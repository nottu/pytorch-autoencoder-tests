{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm   import tqdm_notebook as tqdm\n",
    "from pandas import read_fwf, DataFrame\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radioreader import *\n",
    "from methods import *\n",
    "from kittler import kittler_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Variational Auto Encoder\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, lt_dim=10):\n",
    "        super(VAE, self).__init__()\n",
    "        self.k = [1, 16, 32, 64, 128, 256]\n",
    "        encoder_layers = []\n",
    "        decoder_layers = []\n",
    "        \n",
    "        for i in range(len(self.k) - 1):\n",
    "            layer = nn.Conv2d(self.k[i], self.k[i+1], 3, 2, 1, 1)\n",
    "            encoder_layers.append(layer)\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(len(self.k) - 1, 0, -1):\n",
    "            layer = nn.ConvTranspose2d(self.k[i], self.k[i-1], 3, 2, 1, 1)\n",
    "            decoder_layers.append(layer)\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.decoder = nn.Sequential(*decoder_layers[:-1])\n",
    "        \n",
    "        self.fc_mu = nn.Linear(self.k[-1]*2*2, lt_dim)\n",
    "        self.fc_ep = nn.Linear(self.k[-1]*2*2, lt_dim)\n",
    "        \n",
    "        self.fc_dc = nn.Linear(lt_dim, self.k[-1]*2*2)\n",
    "    def encode(self, x):\n",
    "        encoded = self.encoder(x).view(-1, self.k[-1]*2*2)\n",
    "        return self.fc_mu(encoded), self.fc_ep(encoded)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = F.relu(self.fc_dc(x)).view(-1, self.k[-1], 2, 2)\n",
    "        return torch.sigmoid(self.decoder(x))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, var = self.encode(x)\n",
    "        z = self.reparameterize(mu, var)\n",
    "        d = self.decode(z)\n",
    "        return d, mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (fc_ep): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (fc_dc): Linear(in_features=10, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = torch.load('b_vae_model', map_location='cpu')\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRG(data.Dataset):\n",
    "    def __init__(self, images, targets, transform=None):\n",
    "        self.targets = targets\n",
    "        self.data = images\n",
    "        self.data_len = len(self.data)\n",
    "        if(transform == None):\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(180),\n",
    "                transforms.CenterCrop(80),\n",
    "                transforms.Resize(64),\n",
    "                transforms.ToTensor()])\n",
    "        else : self.transform = transform\n",
    "\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        index = index % self.data_len\n",
    "        np_arr = self.data[index, :]\n",
    "        ## reshape np_arr to 28x28\n",
    "        np_arr = np_arr.reshape(128, 128)\n",
    "\n",
    "        ## convert to PIL-image\n",
    "        img = Image.fromarray((np_arr*255).astype('uint8'))\n",
    "\n",
    "        #apply the transformations and return tensors\n",
    "        return self.transform(img), self.targets[index]\n",
    "    def __len__(self):\n",
    "        return self.data_len * 10\n",
    "    def __repr__(self) -> str:\n",
    "        return 'unLRG dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0096793cfa4a45d69fc15f7c3580c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lrg = read_fwf('catalog/mrt-table3.txt', skiprows=41, header=None)\n",
    "labeled = DataFrame({'Name':lrg[0], 'Label':lrg[7]})\n",
    "\n",
    "#load the images\n",
    "names = labeled['Name'].tolist()\n",
    "labels = labeled['Label'].tolist()\n",
    "images = []\n",
    "directory = 'lrg'\n",
    "ext = 'fits'\n",
    "\n",
    "for i in tqdm(range(len(names))):\n",
    "    f_name = '{0}/{1}.{2}'.format(directory, \n",
    "                                  names[i].replace('.','_'), \n",
    "                                  ext)\n",
    "    im = readImg(f_name, normalize=True, sz=128)\n",
    "    im = kittler_float(im, copy=False)\n",
    "    images.append(im.T)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array([ 1 if (l == '1' or l == '1F') else int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.CenterCrop(80),\n",
    "                transforms.Resize(64),\n",
    "                transforms.ToTensor()])\n",
    "trans_img = []\n",
    "for img in images:\n",
    "    img = img.reshape(128, 128)\n",
    "    ## convert to PIL-image\n",
    "    img = Image.fromarray((img*255).astype('uint8'))\n",
    "    imgs_tr = transform(img)\n",
    "    trans_img.append(imgs_tr.numpy())\n",
    "trans_img = np.array(trans_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out, mu, sig = vae(torch.tensor(trans_img))\n",
    "mu = torch.sigmoid(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1037)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels == 0 ), np.sum(labels > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0, tol=1e-5, penalty='l1', dual=False, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.16289166,  0.37581329, -0.27648376,  0.19372355,  0.05984313,\n",
       "         0.        ,  0.31915881,  0.        ,  0.        ,  0.06914613]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(mu.numpy(), labels > 1)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = labels[labels > 1]\n",
    "mu2 = mu.numpy()[labels > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying Compact  0.9358\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(mu.numpy()[labels == 1])\n",
    "print(\"Acc classifying Compact  {:.4f}\".format(1 - np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = l2[l2 < 4]\n",
    "mu3 = mu2[l2 < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.72537577,  2.24699937,  0.76448716,  0.40652161,  1.88855397,\n",
       "        -0.09498197, -0.04941776, -1.82635156,  0.10030751, -0.22051949]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LinearSVC(random_state=0, tol=1e-5, penalty='l1', dual=False, class_weight='balanced')\n",
    "clf2.fit(mu3, l3 == 3)\n",
    "clf2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying FRI  0.8930\n"
     ]
    }
   ],
   "source": [
    "preds = clf2.predict(mu3[l3 == 2])\n",
    "print(\"Acc classifying FRI  {:.4f}\".format(1-np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying FRII  0.8488\n"
     ]
    }
   ],
   "source": [
    "preds = clf2.predict(mu3[l3 == 3])\n",
    "print(\"Acc classifying FRII  {:.4f}\".format(np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4 = l2[l2 > 3]\n",
    "mu4 = mu2[l2 > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.90579154,  1.24737321,  0.29483753, -0.22996249, -0.43764896,\n",
       "         0.55259859, -0.23845465, -1.86844398,  0.        , -0.2323927 ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = LinearSVC(random_state=0, tol=1e-5, penalty='l1', dual=False, class_weight='balanced')\n",
    "clf4.fit(mu4, l4 > 4)\n",
    "clf4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying Bent  0.7190\n"
     ]
    }
   ],
   "source": [
    "preds = clf4.predict(mu4[l4 == 4])\n",
    "print(\"Acc classifying Bent  {:.4f}\".format(1- np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5 = l4[l4 > 4]\n",
    "mu5 = mu4[l4 > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4530156 ,  0.4617024 , -1.28002934, -0.5542719 ,  0.        ,\n",
       "         0.43710752, -1.05770063,  0.87460983, -0.31649865,  0.        ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5 = LinearSVC(random_state=0, tol=1e-5, penalty='l1', dual=False, class_weight='balanced')\n",
    "clf5.fit(mu5, l5 == 6)\n",
    "clf5.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying XRG  0.6829\n"
     ]
    }
   ],
   "source": [
    "preds = clf5.predict(mu5[l5 == 5])\n",
    "print(\"Acc classifying XRG  {:.4f}\".format(1- np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc classifying RRG  0.7500\n"
     ]
    }
   ],
   "source": [
    "preds = clf5.predict(mu5[l5 == 6])\n",
    "print(\"Acc classifying RRG  {:.4f}\".format(np.sum(preds) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
