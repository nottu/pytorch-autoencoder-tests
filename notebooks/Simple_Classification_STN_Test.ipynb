{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_fwf, DataFrame\n",
    "from tqdm   import tqdm_notebook as tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage.io import imsave\n",
    "from skimage.filters import gaussian as gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import filters\n",
    "from skimage.morphology import opening, closing, disk, binary_dilation, flood\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from VAE.rg_dataset import LRG, BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "aug = 10\n",
    "data_path = '../data/'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/lrg:\t1442/1442\n"
     ]
    }
   ],
   "source": [
    "lrg_data_set   = LRG(112, rd_sz=128, use_kittler=True, n_aug=aug, blur=False, \n",
    "                     catalog_dir=data_path + 'catalog/mrt-table3.txt', \n",
    "                     file_dir=data_path + 'lrg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = lrg_data_set.get_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BasicDataset(X_train, y_train, n_aug=5, sz=112) #\n",
    "test_dataset  = BasicDataset(X_test,  y_test,  n_aug=5,  sz=112)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader  = data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = iter(test_dataloader).next()\n",
    "plt.imshow(sample[0].numpy()[10][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DeepClassifier(k=cfgs['vgg11'], batchnorm=False, use_stn=True)\n",
    "# model(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepClassifier(nn.Module):\n",
    "    ''' Somewhat inspired in VGG\n",
    "        Adds option for STN network\n",
    "    '''\n",
    "    def __init__(self, k=None, num_classes=6, lt_dim=8, batchnorm=True, use_stn=False, in_channels=1, non_linearity=nn.ReLU,\n",
    "                 Conv2d=nn.Conv2d, MaxPool2d=nn.MaxPool2d, BatchNorm2d=nn.BatchNorm2d):\n",
    "        super(DeepClassifier, self).__init__()\n",
    "        \n",
    "        self.use_stn = use_stn\n",
    "        self.non_linearity = non_linearity\n",
    "        self.Conv2d = Conv2d\n",
    "        self.MaxPool2d = MaxPool2d\n",
    "        self.BatchNorm2d = BatchNorm2d\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, lt_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(lt_dim, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d((3, 3))\n",
    "        )\n",
    "        \n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "        \n",
    "        if k == None:\n",
    "            k = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "        layers = self.__make_layers(k, batchnorm)\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def __make_layers(self, k, batch_norm, in_channels=1):\n",
    "        layers = []\n",
    "        for v in k:\n",
    "            if v == 'M' :\n",
    "                layers += [self.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else :\n",
    "                conv2d = self.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, self.BatchNorm2d(v), self.non_linearity(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, self.non_linearity(inplace=True)]\n",
    "                in_channels = v\n",
    "#         for l in layers: print(l)\n",
    "        return layers\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.use_stn:\n",
    "            x = self.stn(x)\n",
    "        \n",
    "        y = self.features(x)\n",
    "        y = self.avgpool(y)\n",
    "        y = torch.flatten(y, 1)\n",
    "        y = self.classifier(y)\n",
    "        return y\n",
    "\n",
    "'''Common configs for VGG like networks'''\n",
    "cfgs = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, epoch, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_inputs=0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        running_inputs += len(labels.data)\n",
    "        \n",
    "        running_acc = (1.0 * running_corrects)/running_inputs\n",
    "        \n",
    "        \n",
    "        s = 'Train Epoch: {:3d} ({:3.0f}%)\\tLoss:\\t{:4.4f}\\trLoss: {:4.2f}\\tTrain Acc: {:.4f}'\n",
    "        s = s.format(epoch,\n",
    "                100. * batch_idx / len(dataloader), loss.item(), running_loss, running_acc)\n",
    "        sys.stdout.write('{}\\r'.format(s))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        del loss, _, preds, outputs\n",
    "    del running_corrects\n",
    "    return running_loss, running_acc, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, optimizer, epoch, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_inputs=0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        running_inputs += len(labels.data)\n",
    "        \n",
    "        running_acc = (1.0 * running_corrects)/running_inputs\n",
    "        \n",
    "#         s = 'Test Epoch: {:3d} ({:3.0f}%)\\tLoss:\\t{:4.4f}\\trLoss: {:4.2f}\\trPreds: {:.4f}'\n",
    "#         s = s.format(epoch,\n",
    "#                 100. * batch_idx / len(dataloader), loss.item(), running_loss, running_acc)\n",
    "#         sys.stdout.write('{}\\r'.format(s))\n",
    "#         sys.stdout.flush()\n",
    "\n",
    "        del loss, _, preds, outputs\n",
    "    del running_corrects\n",
    "    return running_loss, running_acc#, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   1 ( 99%)\tLoss:\t1.6731\trLoss: 15498.29\tTrain Acc: 0.2914 Test Acc: 0.2818\tTime: 15.4923\n",
      "Train Epoch:   2 ( 99%)\tLoss:\t1.6919\trLoss: 15099.21\tTrain Acc: 0.3086 Test Acc: 0.4123\tTime: 14.9939\n",
      "Train Epoch:   3 ( 99%)\tLoss:\t1.4645\trLoss: 14722.11\tTrain Acc: 0.3947 Test Acc: 0.3826\tTime: 14.9387\n",
      "Train Epoch:   4 ( 99%)\tLoss:\t1.1907\trLoss: 13937.33\tTrain Acc: 0.4399 Test Acc: 0.4309\tTime: 14.8207\n",
      "Train Epoch:   5 ( 99%)\tLoss:\t1.1610\trLoss: 13117.36\tTrain Acc: 0.4544 Test Acc: 0.4343\tTime: 14.8124\n",
      "Train Epoch:   6 ( 99%)\tLoss:\t1.0493\trLoss: 12923.18\tTrain Acc: 0.4572 Test Acc: 0.4424\tTime: 14.8105\n",
      "Train Epoch:   7 ( 99%)\tLoss:\t1.2911\trLoss: 12685.62\tTrain Acc: 0.4569 Test Acc: 0.4301\tTime: 14.8107\n",
      "Train Epoch:   8 ( 99%)\tLoss:\t1.0287\trLoss: 11976.85\tTrain Acc: 0.4720 Test Acc: 0.4767\tTime: 14.8035\n",
      "Train Epoch:   9 ( 99%)\tLoss:\t1.0315\trLoss: 11136.39\tTrain Acc: 0.4905 Test Acc: 0.4992\tTime: 14.8171\n",
      "Train Epoch:  10 ( 99%)\tLoss:\t1.2063\trLoss: 10844.38\tTrain Acc: 0.4913 Test Acc: 0.4932\tTime: 14.7836\n",
      "Train Epoch:  11 ( 99%)\tLoss:\t1.1661\trLoss: 10526.23\tTrain Acc: 0.5015 Test Acc: 0.4979\tTime: 14.7566\n",
      "Train Epoch:  12 ( 99%)\tLoss:\t1.0512\trLoss: 10385.83\tTrain Acc: 0.5095 Test Acc: 0.5191\tTime: 14.8067\n",
      "Train Epoch:  13 ( 99%)\tLoss:\t1.0234\trLoss: 10139.49\tTrain Acc: 0.5306 Test Acc: 0.6021\tTime: 14.8316\n",
      "Train Epoch:  14 ( 99%)\tLoss:\t1.1921\trLoss: 10029.92\tTrain Acc: 0.5450 Test Acc: 0.6436\tTime: 14.9549\n",
      "Train Epoch:  15 ( 99%)\tLoss:\t1.0112\trLoss: 9904.38\tTrain Acc: 0.5572 Test Acc: 0.6496\tTime: 14.8938\n",
      "Train Epoch:  16 ( 99%)\tLoss:\t1.1672\trLoss: 9795.51\tTrain Acc: 0.5841 Test Acc: 0.6275\tTime: 14.8842\n",
      "Train Epoch:  17 ( 99%)\tLoss:\t1.0185\trLoss: 9658.90\tTrain Acc: 0.5906 Test Acc: 0.6682\tTime: 14.9176\n",
      "Train Epoch:  18 ( 99%)\tLoss:\t1.1249\trLoss: 9622.66\tTrain Acc: 0.5896 Test Acc: 0.6733\tTime: 14.8672\n",
      "Train Epoch:  19 ( 99%)\tLoss:\t1.1565\trLoss: 9348.69\tTrain Acc: 0.6083 Test Acc: 0.6081\tTime: 14.7907\n",
      "Train Epoch:  20 ( 99%)\tLoss:\t0.8252\trLoss: 9315.61\tTrain Acc: 0.6091 Test Acc: 0.6729\tTime: 14.9111\n",
      "Train Epoch:  21 ( 99%)\tLoss:\t1.0324\trLoss: 9241.43\tTrain Acc: 0.6173 Test Acc: 0.5839\tTime: 14.9245\n",
      "Train Epoch:  22 ( 99%)\tLoss:\t0.9629\trLoss: 8970.80\tTrain Acc: 0.6315 Test Acc: 0.6441\tTime: 14.9740\n",
      "Train Epoch:  23 ( 99%)\tLoss:\t0.8975\trLoss: 8891.81\tTrain Acc: 0.6373 Test Acc: 0.6733\tTime: 15.0249\n",
      "Train Epoch:  24 ( 99%)\tLoss:\t1.0013\trLoss: 8886.22\tTrain Acc: 0.6376 Test Acc: 0.5958\tTime: 14.9110\n",
      "Train Epoch:  25 ( 99%)\tLoss:\t0.7477\trLoss: 8885.06\tTrain Acc: 0.6351 Test Acc: 0.6678\tTime: 14.9869\n",
      "Train Epoch:  26 ( 99%)\tLoss:\t1.1629\trLoss: 8773.91\tTrain Acc: 0.6388 Test Acc: 0.5953\tTime: 15.0343\n",
      "Train Epoch:  27 ( 99%)\tLoss:\t0.7735\trLoss: 8714.76\tTrain Acc: 0.6463 Test Acc: 0.6818\tTime: 15.0371\n",
      "Train Epoch:  28 ( 99%)\tLoss:\t0.9857\trLoss: 8576.78\tTrain Acc: 0.6545 Test Acc: 0.6703\tTime: 15.0175\n",
      "Train Epoch:  29 ( 99%)\tLoss:\t0.6829\trLoss: 8615.69\tTrain Acc: 0.6506 Test Acc: 0.6034\tTime: 14.9374\n",
      "Train Epoch:  30 ( 99%)\tLoss:\t0.7640\trLoss: 8531.46\tTrain Acc: 0.6514 Test Acc: 0.6606\tTime: 14.9902\n",
      "Train Epoch:  31 ( 99%)\tLoss:\t1.1167\trLoss: 8527.50\tTrain Acc: 0.6546 Test Acc: 0.6835\tTime: 15.0499\n",
      "Train Epoch:  32 ( 99%)\tLoss:\t0.8253\trLoss: 8425.25\tTrain Acc: 0.6617 Test Acc: 0.7186\tTime: 15.0076\n",
      "Train Epoch:  33 ( 99%)\tLoss:\t0.9609\trLoss: 8288.87\tTrain Acc: 0.6673 Test Acc: 0.6809\tTime: 14.9675\n",
      "Train Epoch:  34 ( 99%)\tLoss:\t0.9670\trLoss: 8398.54\tTrain Acc: 0.6608 Test Acc: 0.6335\tTime: 14.9736\n",
      "Train Epoch:  35 ( 99%)\tLoss:\t0.8729\trLoss: 8279.80\tTrain Acc: 0.6642 Test Acc: 0.6538\tTime: 14.8952\n",
      "Train Epoch:  36 ( 99%)\tLoss:\t0.7075\trLoss: 8257.66\tTrain Acc: 0.6666 Test Acc: 0.7191\tTime: 14.8456\n",
      "Train Epoch:  37 ( 99%)\tLoss:\t0.6923\trLoss: 8244.52\tTrain Acc: 0.6668 Test Acc: 0.5398\tTime: 15.0140\n",
      "Train Epoch:  38 ( 99%)\tLoss:\t0.9341\trLoss: 8120.81\tTrain Acc: 0.6754 Test Acc: 0.6347\tTime: 14.9888\n",
      "Train Epoch:  39 ( 99%)\tLoss:\t0.6461\trLoss: 7917.57\tTrain Acc: 0.6806 Test Acc: 0.6390\tTime: 15.0058\n",
      "Train Epoch:  40 ( 99%)\tLoss:\t1.0084\trLoss: 7756.52\tTrain Acc: 0.6900 Test Acc: 0.6288\tTime: 14.9067\n",
      "Train Epoch:  41 ( 99%)\tLoss:\t0.9299\trLoss: 7690.94\tTrain Acc: 0.7008 Test Acc: 0.5822\tTime: 14.9932\n",
      "Train Epoch:  42 ( 99%)\tLoss:\t1.0080\trLoss: 7708.83\tTrain Acc: 0.7032 Test Acc: 0.6466\tTime: 15.1498\n",
      "Train Epoch:  43 ( 99%)\tLoss:\t0.7301\trLoss: 7562.85\tTrain Acc: 0.7050 Test Acc: 0.6530\tTime: 15.5134\n",
      "Train Epoch:  44 ( 99%)\tLoss:\t0.8355\trLoss: 7581.80\tTrain Acc: 0.7039 Test Acc: 0.6928\tTime: 15.4994\n",
      "Train Epoch:  45 ( 99%)\tLoss:\t0.7535\trLoss: 7384.81\tTrain Acc: 0.7168 Test Acc: 0.6890\tTime: 15.2743\n",
      "Train Epoch:  46 ( 99%)\tLoss:\t0.6761\trLoss: 7445.50\tTrain Acc: 0.7112 Test Acc: 0.6614\tTime: 14.9664\n",
      "Train Epoch:  47 ( 99%)\tLoss:\t0.7423\trLoss: 7331.53\tTrain Acc: 0.7215 Test Acc: 0.6720\tTime: 14.8245\n",
      "Train Epoch:  48 ( 99%)\tLoss:\t0.8682\trLoss: 7469.94\tTrain Acc: 0.7063 Test Acc: 0.6220\tTime: 15.1852\n",
      "Train Epoch:  49 ( 99%)\tLoss:\t0.7092\trLoss: 7335.44\tTrain Acc: 0.7193 Test Acc: 0.6559\tTime: 15.0442\n",
      "Train Epoch:  50 ( 99%)\tLoss:\t0.6380\trLoss: 7212.49\tTrain Acc: 0.7247 Test Acc: 0.6436\tTime: 15.0414\n",
      "Train Epoch:  51 ( 99%)\tLoss:\t0.7066\trLoss: 7262.73\tTrain Acc: 0.7231 Test Acc: 0.6356\tTime: 15.2775\n",
      "Train Epoch:  52 ( 99%)\tLoss:\t0.6616\trLoss: 7254.52\tTrain Acc: 0.7197 Test Acc: 0.6381\tTime: 15.6150\n",
      "Train Epoch:  53 ( 99%)\tLoss:\t0.6563\trLoss: 7159.69\tTrain Acc: 0.7263 Test Acc: 0.6797\tTime: 15.1365\n",
      "Train Epoch:  54 ( 99%)\tLoss:\t0.7781\trLoss: 7184.10\tTrain Acc: 0.7241 Test Acc: 0.7047\tTime: 15.0064\n",
      "Train Epoch:  55 ( 99%)\tLoss:\t0.8087\trLoss: 7045.55\tTrain Acc: 0.7326 Test Acc: 0.6551\tTime: 15.0594\n",
      "Train Epoch:  56 ( 99%)\tLoss:\t1.1797\trLoss: 6958.52\tTrain Acc: 0.7367 Test Acc: 0.6182\tTime: 15.2769\n",
      "Train Epoch:  57 ( 99%)\tLoss:\t0.8718\trLoss: 7023.03\tTrain Acc: 0.7354 Test Acc: 0.6085\tTime: 14.9218\n",
      "Train Epoch:  58 ( 99%)\tLoss:\t0.8527\trLoss: 7020.03\tTrain Acc: 0.7323 Test Acc: 0.5788\tTime: 15.0051\n",
      "Train Epoch:  59 ( 99%)\tLoss:\t0.8141\trLoss: 7003.66\tTrain Acc: 0.7328 Test Acc: 0.6458\tTime: 14.9901\n",
      "Train Epoch:  60 ( 99%)\tLoss:\t0.3751\trLoss: 6831.24\tTrain Acc: 0.7441 Test Acc: 0.6597\tTime: 15.0505\n",
      "Train Epoch:  61 ( 99%)\tLoss:\t0.8294\trLoss: 6943.19\tTrain Acc: 0.7406 Test Acc: 0.6403\tTime: 15.0241\n",
      "Train Epoch:  62 ( 99%)\tLoss:\t0.7370\trLoss: 6782.10\tTrain Acc: 0.7435 Test Acc: 0.6831\tTime: 14.9492\n",
      "Train Epoch:  63 ( 99%)\tLoss:\t0.9010\trLoss: 6762.05\tTrain Acc: 0.7442 Test Acc: 0.6390\tTime: 15.1092\n",
      "Train Epoch:  64 ( 99%)\tLoss:\t0.8069\trLoss: 6799.37\tTrain Acc: 0.7423 Test Acc: 0.6449\tTime: 15.1153\n",
      "Train Epoch:  65 ( 99%)\tLoss:\t0.7574\trLoss: 6568.63\tTrain Acc: 0.7564 Test Acc: 0.6292\tTime: 15.1650\n",
      "Train Epoch:  66 ( 99%)\tLoss:\t0.7694\trLoss: 6697.50\tTrain Acc: 0.7514 Test Acc: 0.6805\tTime: 15.0672\n",
      "Train Epoch:  67 ( 99%)\tLoss:\t0.7925\trLoss: 6647.15\tTrain Acc: 0.7531 Test Acc: 0.6225\tTime: 15.1022\n",
      "Train Epoch:  68 ( 99%)\tLoss:\t0.7303\trLoss: 6511.13\tTrain Acc: 0.7569 Test Acc: 0.6555\tTime: 15.0737\n",
      "Train Epoch:  69 ( 99%)\tLoss:\t0.6194\trLoss: 6568.85\tTrain Acc: 0.7554 Test Acc: 0.6936\tTime: 14.9360\n",
      "Train Epoch:  70 ( 99%)\tLoss:\t0.5974\trLoss: 6448.85\tTrain Acc: 0.7575 Test Acc: 0.6780\tTime: 14.9322\n",
      "Train Epoch:  71 ( 99%)\tLoss:\t0.8106\trLoss: 6379.83\tTrain Acc: 0.7633 Test Acc: 0.6203\tTime: 14.9677\n",
      "Train Epoch:  72 ( 99%)\tLoss:\t0.7149\trLoss: 6371.81\tTrain Acc: 0.7614 Test Acc: 0.6712\tTime: 15.0058\n",
      "Train Epoch:  73 ( 99%)\tLoss:\t1.0577\trLoss: 6324.77\tTrain Acc: 0.7661 Test Acc: 0.6445\tTime: 14.9298\n",
      "Train Epoch:  74 ( 99%)\tLoss:\t0.5748\trLoss: 6260.45\tTrain Acc: 0.7673 Test Acc: 0.6835\tTime: 15.0745\n",
      "Train Epoch:  75 ( 99%)\tLoss:\t0.7970\trLoss: 6158.78\tTrain Acc: 0.7728 Test Acc: 0.6907\tTime: 14.9404\n",
      "Train Epoch:  76 ( 99%)\tLoss:\t0.8790\trLoss: 6093.58\tTrain Acc: 0.7705 Test Acc: 0.6695\tTime: 15.0592\n",
      "Train Epoch:  77 ( 99%)\tLoss:\t0.4277\trLoss: 6099.99\tTrain Acc: 0.7724 Test Acc: 0.6534\tTime: 15.0672\n",
      "Train Epoch:  78 ( 99%)\tLoss:\t0.5995\trLoss: 5995.65\tTrain Acc: 0.7748 Test Acc: 0.6102\tTime: 14.9097\n",
      "Train Epoch:  79 ( 99%)\tLoss:\t0.4799\trLoss: 5941.40\tTrain Acc: 0.7732 Test Acc: 0.6733\tTime: 15.0111\n",
      "Train Epoch:  80 ( 99%)\tLoss:\t0.5273\trLoss: 6003.91\tTrain Acc: 0.7698 Test Acc: 0.6754\tTime: 15.0872\n",
      "Train Epoch:  81 ( 99%)\tLoss:\t0.4523\trLoss: 5843.56\tTrain Acc: 0.7788 Test Acc: 0.6911\tTime: 14.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  82 ( 99%)\tLoss:\t0.6851\trLoss: 5866.20\tTrain Acc: 0.7754 Test Acc: 0.6797\tTime: 14.8608\n",
      "Train Epoch:  83 ( 99%)\tLoss:\t0.5526\trLoss: 5866.01\tTrain Acc: 0.7736 Test Acc: 0.7093\tTime: 14.8014\n",
      "Train Epoch:  84 ( 99%)\tLoss:\t0.7185\trLoss: 6034.68\tTrain Acc: 0.7750 Test Acc: 0.6407\tTime: 14.8314\n",
      "Train Epoch:  85 ( 99%)\tLoss:\t0.6625\trLoss: 5697.39\tTrain Acc: 0.7805 Test Acc: 0.6525\tTime: 14.8539\n",
      "Train Epoch:  86 ( 99%)\tLoss:\t0.6125\trLoss: 5698.62\tTrain Acc: 0.7812 Test Acc: 0.6894\tTime: 14.8053\n",
      "Train Epoch:  87 ( 99%)\tLoss:\t0.7254\trLoss: 5652.44\tTrain Acc: 0.7848 Test Acc: 0.6822\tTime: 14.8949\n",
      "Train Epoch:  88 ( 99%)\tLoss:\t0.6799\trLoss: 5624.75\tTrain Acc: 0.7828 Test Acc: 0.6504\tTime: 14.8807\n",
      "Train Epoch:  89 ( 99%)\tLoss:\t0.4850\trLoss: 5603.39\tTrain Acc: 0.7890 Test Acc: 0.7233\tTime: 14.9000\n",
      "Train Epoch:  90 ( 99%)\tLoss:\t0.3229\trLoss: 5469.29\tTrain Acc: 0.7884 Test Acc: 0.7314\tTime: 14.8745\n",
      "Train Epoch:  91 ( 99%)\tLoss:\t0.6547\trLoss: 5295.84\tTrain Acc: 0.7926 Test Acc: 0.6966\tTime: 14.8905\n",
      "Train Epoch:  92 ( 99%)\tLoss:\t0.4974\trLoss: 5109.98\tTrain Acc: 0.8000 Test Acc: 0.7025\tTime: 14.8769\n",
      "Train Epoch:  93 ( 99%)\tLoss:\t0.5139\trLoss: 5089.44\tTrain Acc: 0.7993 Test Acc: 0.6691\tTime: 14.9568\n",
      "Train Epoch:  94 ( 99%)\tLoss:\t0.7860\trLoss: 5099.55\tTrain Acc: 0.8048 Test Acc: 0.7157\tTime: 14.8759\n",
      "Train Epoch:  95 ( 99%)\tLoss:\t0.4240\trLoss: 4957.30\tTrain Acc: 0.8075 Test Acc: 0.6945\tTime: 14.8446\n",
      "Train Epoch:  96 ( 99%)\tLoss:\t0.4911\trLoss: 4997.27\tTrain Acc: 0.8043 Test Acc: 0.7008\tTime: 14.8975\n",
      "Train Epoch:  97 ( 99%)\tLoss:\t0.3185\trLoss: 5012.79\tTrain Acc: 0.8062 Test Acc: 0.7178\tTime: 14.8890\n",
      "Train Epoch:  98 ( 99%)\tLoss:\t0.8267\trLoss: 4907.04\tTrain Acc: 0.8106 Test Acc: 0.6665\tTime: 14.9030\n",
      "Train Epoch:  99 ( 99%)\tLoss:\t0.2657\trLoss: 4842.80\tTrain Acc: 0.8125 Test Acc: 0.6708\tTime: 14.9682\n",
      "Train Epoch: 100 ( 99%)\tLoss:\t0.3160\trLoss: 4852.67\tTrain Acc: 0.8107 Test Acc: 0.6873\tTime: 14.9143\n"
     ]
    }
   ],
   "source": [
    "model = DeepClassifier(k=cfgs['vgg11'], batchnorm=False, use_stn=True).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=1E-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.time()\n",
    "    train_l, train_c, train_s = train(model, train_dataloader, optimizer, epoch, criterion)\n",
    "    test_l,  test_c           = test(model,  test_dataloader,  optimizer, epoch, criterion)\n",
    "    t = time.time() - start\n",
    "    print(train_s, 'Test Acc: {:.4f}\\tTime: {:.4f}'.format(test_c, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DeepClassifier(k=cfgs['vgg11'], batchnorm=True).to(device)\n",
    "# optimizer = Adam(model.parameters(), lr=lr, weight_decay=1E-5)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(1, epochs+1):\n",
    "#     start = time.time()\n",
    "#     train_l, train_c, train_s = train(model, train_dataloader, optimizer, epoch, criterion)\n",
    "#     test_l,  test_c           = test(model,  test_dataloader,  optimizer, epoch, criterion)\n",
    "#     t = time.time() - start\n",
    "#     print(train_s, 'Test Acc: {:.4f}\\tTime: {:.4f}'.format(test_c, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RotEqNet.layers_2D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotEqDeepClassifier(nn.Module):\n",
    "    ''' Somewhat inspired in VGG\n",
    "        Adds option for STN network\n",
    "    '''\n",
    "    def __init__(self, k=None, num_classes=6, lt_dim=8, batchnorm=True, in_channels=1, non_linearity=nn.ReLU):\n",
    "        super(RotEqDeepClassifier, self).__init__()\n",
    "        \n",
    "        self.non_linearity = non_linearity\n",
    "                \n",
    "        if k == None:\n",
    "            k = [32, 'M', 64, 'M', 128, 128, 'M', 'R', 256, 256, 'M']\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(k[-2] * 7 * 7, lt_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(lt_dim, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "        layers = self.__make_layers(k, batchnorm)\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def __make_layers(self, k, batch_norm, in_channels=1, mode=1):\n",
    "        layers = []\n",
    "        use_rot = True\n",
    "        for v in k:\n",
    "#             print('=============================',k,'====================')\n",
    "            if v == 'R':\n",
    "                use_rot = False\n",
    "                conv2d = RotConv(in_channels, in_channels, kernel_size=[3,3], padding=1, mode=mode, n_angles = 17)\n",
    "                layers += [conv2d, Vector2Magnitude()]\n",
    "            elif v == 'M' :\n",
    "                if use_rot:\n",
    "                    layers += [VectorMaxPool(kernel_size=2, stride=2)]\n",
    "                else:\n",
    "                    layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else :\n",
    "                if use_rot:\n",
    "                    conv2d = RotConv(in_channels, v, kernel_size=[3,3], padding=1, mode=mode, n_angles = 17)\n",
    "                else:\n",
    "                    conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    if use_rot:\n",
    "                        layers += [conv2d, VectorBatchNorm(v)]\n",
    "                    else:\n",
    "                        layers += [conv2d, nn.BatchNorm2d(v), self.non_linearity(inplace=True)]\n",
    "                else:\n",
    "                    if use_rot:\n",
    "                        layers += [conv2d]\n",
    "                    else:\n",
    "                        layers += [conv2d, self.non_linearity(inplace=True)]\n",
    "                in_channels = v\n",
    "                mode = 2\n",
    "#         for l in layers : print(l)\n",
    "        return layers\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.features(x)\n",
    "        y = self.avgpool(y)\n",
    "        y = torch.flatten(y, 1)\n",
    "        y = self.classifier(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.features[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RotEqDeepClassifier(batchnorm=False).to(device)\n",
    "# o = model(sample[0].to(device))\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   1 ( 99%)\tLoss:\t1.4438\trLoss: 7990.98\tTrain Acc: 0.2890 Test Acc: 0.2903\tTime: 112.3038\n",
      "Train Epoch:   2 ( 99%)\tLoss:\t1.5547\trLoss: 7554.60\tTrain Acc: 0.2832 Test Acc: 0.2903\tTime: 112.1237\n",
      "Train Epoch:   3 ( 99%)\tLoss:\t1.6038\trLoss: 7491.57\tTrain Acc: 0.2995 Test Acc: 0.2669\tTime: 112.3508\n",
      "Train Epoch:   4 ( 99%)\tLoss:\t1.4653\trLoss: 7485.11\tTrain Acc: 0.2989 Test Acc: 0.2903\tTime: 112.5409\n",
      "Train Epoch:   5 ( 99%)\tLoss:\t1.5413\trLoss: 7434.03\tTrain Acc: 0.2853 Test Acc: 0.2903\tTime: 112.4355\n",
      "Train Epoch:   6 ( 99%)\tLoss:\t1.4584\trLoss: 7429.89\tTrain Acc: 0.2905 Test Acc: 0.2903\tTime: 112.4700\n",
      "Train Epoch:   7 ( 99%)\tLoss:\t1.7141\trLoss: 7412.95\tTrain Acc: 0.2951 Test Acc: 0.2903\tTime: 112.5302\n",
      "Train Epoch:   8 ( 99%)\tLoss:\t1.3988\trLoss: 7413.53\tTrain Acc: 0.2825 Test Acc: 0.2903\tTime: 112.4742\n",
      "Train Epoch:   9 ( 99%)\tLoss:\t1.6637\trLoss: 7411.23\tTrain Acc: 0.2940 Test Acc: 0.2669\tTime: 112.4214\n",
      "Train Epoch:  10 ( 99%)\tLoss:\t1.6048\trLoss: 7411.82\tTrain Acc: 0.3005 Test Acc: 0.2903\tTime: 112.4076\n",
      "Train Epoch:  11 ( 99%)\tLoss:\t1.6077\trLoss: 7409.75\tTrain Acc: 0.2953 Test Acc: 0.2903\tTime: 112.4547\n",
      "Train Epoch:  12 ( 99%)\tLoss:\t1.9732\trLoss: 7411.28\tTrain Acc: 0.2920 Test Acc: 0.2903\tTime: 112.3900\n",
      "Train Epoch:  13 ( 99%)\tLoss:\t1.5837\trLoss: 7412.89\tTrain Acc: 0.2882 Test Acc: 0.2903\tTime: 112.4112\n",
      "Train Epoch:  14 ( 99%)\tLoss:\t1.6372\trLoss: 7410.24\tTrain Acc: 0.2828 Test Acc: 0.2903\tTime: 112.4867\n",
      "Train Epoch:  15 ( 99%)\tLoss:\t1.5743\trLoss: 7407.53\tTrain Acc: 0.2882 Test Acc: 0.2903\tTime: 112.4540\n",
      "Train Epoch:  16 ( 99%)\tLoss:\t1.6709\trLoss: 7407.24\tTrain Acc: 0.2991 Test Acc: 0.2903\tTime: 112.3694\n",
      "Train Epoch:  17 ( 99%)\tLoss:\t1.3243\trLoss: 7410.50\tTrain Acc: 0.2855 Test Acc: 0.2903\tTime: 112.4717\n",
      "Train Epoch:  18 ( 99%)\tLoss:\t1.5144\trLoss: 7408.45\tTrain Acc: 0.2930 Test Acc: 0.2903\tTime: 112.4275\n",
      "Train Epoch:  19 ( 99%)\tLoss:\t1.7010\trLoss: 7407.29\tTrain Acc: 0.2934 Test Acc: 0.2669\tTime: 112.4140\n",
      "Train Epoch:  20 ( 99%)\tLoss:\t1.8063\trLoss: 7406.02\tTrain Acc: 0.2951 Test Acc: 0.2669\tTime: 112.3835\n",
      "Train Epoch:  21 ( 99%)\tLoss:\t1.4563\trLoss: 7405.68\tTrain Acc: 0.2825 Test Acc: 0.2903\tTime: 112.5186\n",
      "Train Epoch:  22 ( 99%)\tLoss:\t1.5159\trLoss: 7408.51\tTrain Acc: 0.2911 Test Acc: 0.2903\tTime: 112.5366\n",
      "Train Epoch:  23 ( 99%)\tLoss:\t1.4869\trLoss: 7409.07\tTrain Acc: 0.2966 Test Acc: 0.2903\tTime: 112.1891\n",
      "Train Epoch:  24 ( 99%)\tLoss:\t1.2480\trLoss: 7408.45\tTrain Acc: 0.2959 Test Acc: 0.2903\tTime: 112.3951\n",
      "Train Epoch:  25 ( 99%)\tLoss:\t1.4483\trLoss: 7407.44\tTrain Acc: 0.2955 Test Acc: 0.2903\tTime: 112.3379\n",
      "Train Epoch:  26 ( 99%)\tLoss:\t1.5254\trLoss: 7406.50\tTrain Acc: 0.2959 Test Acc: 0.2903\tTime: 112.4108\n",
      "Train Epoch:  27 ( 99%)\tLoss:\t1.7479\trLoss: 7404.14\tTrain Acc: 0.2848 Test Acc: 0.2903\tTime: 112.3705\n",
      "Train Epoch:  28 ( 99%)\tLoss:\t1.3631\trLoss: 7407.90\tTrain Acc: 0.2953 Test Acc: 0.2903\tTime: 112.4131\n",
      "Train Epoch:  29 ( 99%)\tLoss:\t1.5032\trLoss: 7407.32\tTrain Acc: 0.2888 Test Acc: 0.2903\tTime: 112.4268\n",
      "Train Epoch:  30 ( 99%)\tLoss:\t1.4750\trLoss: 7404.70\tTrain Acc: 0.2991 Test Acc: 0.2903\tTime: 112.2647\n",
      "Train Epoch:  31 ( 99%)\tLoss:\t1.4757\trLoss: 7405.43\tTrain Acc: 0.2961 Test Acc: 0.2903\tTime: 112.5000\n",
      "Train Epoch:  32 ( 99%)\tLoss:\t1.5050\trLoss: 7406.26\tTrain Acc: 0.2803 Test Acc: 0.2903\tTime: 112.3905\n",
      "Train Epoch:  33 ( 99%)\tLoss:\t1.7849\trLoss: 7404.67\tTrain Acc: 0.2986 Test Acc: 0.2903\tTime: 112.5460\n",
      "Train Epoch:  34 ( 33%)\tLoss:\t1.4654\trLoss: 2526.73\tTrain Acc: 0.2984\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1928306aa34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_l\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_c\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0c2b6b788cfe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-28f21e25a730>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-autoencoder-tests/RotEqNet/layers_2D.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;31m# Apply rotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mwu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-autoencoder-tests/RotEqNet/utils.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(filter, interp_vars, filters_size, old_bilinear_interpolation)\u001b[0m\n\u001b[1;32m    149\u001b[0m                           \u001b[0mfilter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                           \u001b[0mfilter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                           filter[:, :, x0_1, x1_1] * w0 * w1)\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RotEqDeepClassifier(batchnorm=False).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=1E-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model.half()  # convert to half precision\n",
    "# for layer in model.modules():\n",
    "#     if isinstance(layer, nn.BatchNorm2d) or isinstance(layer, VectorBatchNorm):\n",
    "#         layer.float()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.time()\n",
    "    train_l, train_c, train_s = train(model, train_dataloader, optimizer, epoch, criterion)\n",
    "    test_l,  test_c           = test(model,  test_dataloader,  optimizer, epoch, criterion)\n",
    "    t = time.time() - start\n",
    "    print(train_s, 'Test Acc: {:.4f}\\tTime: {:.4f}'.format(test_c, t))\n",
    "    del train_l, train_c, test_l,  test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
