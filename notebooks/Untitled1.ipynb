{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_fwf, DataFrame\n",
    "from tqdm   import tqdm_notebook as tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage.io import imsave\n",
    "from skimage.filters import gaussian as gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import filters\n",
    "from skimage.morphology import opening, closing, disk, binary_dilation, flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from VAE.rg_dataset import LRG, BasicDataset\n",
    "from VAE.vae_models import VAE\n",
    "from VAE.loss_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "n_aug = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/lrg:\t1442/1442\n",
      "../data/unlrg:\t14245/14245\n",
      "CPU times: user 6min 2s, sys: 6min 32s, total: 12min 35s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lrg_data_set   = LRG(use_kittler=True, n_aug=n_aug, blur=False, catalog_dir=data_path + 'catalog/mrt-table3.txt', \n",
    "                                                  twice=False, file_dir=data_path + 'lrg')\n",
    "\n",
    "unlrg_data_set = LRG(use_kittler=True, n_aug=n_aug, blur=False, catalog_dir=data_path + 'catalog/mrt-table4.txt',\n",
    "                                                  twice=True, file_dir=data_path + 'unlrg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_lrg   = data.DataLoader(lrg_data_set,   batch_size=batch_size, shuffle=False)\n",
    "data_loader_unlrg = data.DataLoader(unlrg_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "sample = iter(data_loader_lrg).next()\n",
    "sampleunlrg = iter(data_loader_unlrg).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55d4a9a0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "lr=0.001\n",
    "n_epochs = 50\n",
    "\n",
    "gam = 1\n",
    "cap = 10\n",
    "decay  = 0.015\n",
    "lt_dim = 8\n",
    "\n",
    "k=[1, 64, 128, 128, 256, 256] # number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vae_loss = B_VAE_Loss_cap(gamma=gam, max_capacity=cap, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(lt_dim, k).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5147, -0.3727,  0.1991,  ..., -0.0980,  0.2960, -0.2858],\n",
       "        [-0.6257, -0.2372, -0.4030,  ...,  0.2359,  0.3194,  1.2403],\n",
       "        [ 0.5602,  0.0314,  0.3393,  ...,  0.1242,  0.2107, -0.0816],\n",
       "        ...,\n",
       "        [-0.0123, -0.2939, -0.9430,  ..., -0.0877, -0.6125,  0.2424],\n",
       "        [-0.0126,  0.0346,  0.1227,  ...,  0.8152, -0.4348,  0.6037],\n",
       "        [ 1.4222, -0.2740,  0.9530,  ..., -0.1794,  0.0633, -0.5443]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1, v2 = vae.encode(sampleunlrg[0].to(device)), vae.encode(sampleunlrg[1].to(device))\n",
    "\n",
    "# (v2[0] + v1[0]) / 2\n",
    "\n",
    "v3 = (v2[0] + v1[0]) / 2\n",
    "v3[:, -1] = v1[0][:,-1]\n",
    "# v3\n",
    "v2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(vae.parameters(), lr=lr, weight_decay=1E-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_b_vae_cap(model, device, data_loader, optim, epoch, loss_fun, log_interval=5):\n",
    "    model.train()\n",
    "    s = ''\n",
    "    r_loss = 0\n",
    "    batch_sum = 0 \n",
    "    for batch_idx, (data, data1, target) in enumerate(data_loader):\n",
    "        batch_sum += len(data)\n",
    "        data  = data.to(device)\n",
    "        data1 = data1.to(device)\n",
    "        \n",
    "        target = Variable(target, requires_grad=False).to(device)\n",
    "        #Forward Pass\n",
    "        optim.zero_grad()\n",
    "        output1_m, output1_v = model.encode(data)\n",
    "        output2_m, output2_v = model.encode(data1)\n",
    "        \n",
    "        mu  = (output1_m + output2_m) / 2\n",
    "        var = (output1_m + output2_m) / 2\n",
    "        \n",
    "        mu[:, -1]  = output1_m[:, -1]\n",
    "        var[:, -1] = output1_v[:, -1]\n",
    "        \n",
    "        output = model.decode(model.reparameterize(mu, var)), mu, var\n",
    "        #############################################\n",
    "        ######### check against known class #########\n",
    "        #############################################\n",
    "        #########    Compact vs Extended    #########\n",
    "        # ext_loss = compact_extended_loss(target, output[1][:,0], device)\n",
    "        # # #########       FRI vs FRII         #########\n",
    "        # fr_loss = fri_frii_loss(target, output[1][:, 1], device)\n",
    "        # #########   Try to learn rotation   #########\n",
    "        \n",
    "        # Non Rotated part loss\n",
    "        v1, v2 = output1_m[:,:-1], output2_m[:,:-1]\n",
    "        rot_loss = F.mse_loss(v1, v2)\n",
    "        # BCE Loss\n",
    "        c, r_loss , g_loss = loss_fun(output, data)\n",
    "        loss = 30*r_loss + g_loss + rot_loss #+ 20 * (ext_loss + fr_loss)#\n",
    "        #Backpropagation\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        s = 'Train Epoch: {:3d} [{:5d}/{:5d} ({:3.0f}%)]   Loss: {:4.4f}   Rot_Loss: {:4.4f}   Capacity: {:4.2f}'\n",
    "        s = s.format(epoch, batch_sum, len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item(), rot_loss.item(), c)\n",
    "        if batch_idx % log_interval == 0:\n",
    "            sys.stdout.write('{}\\r'.format(s))\n",
    "            sys.stdout.flush()\n",
    "    return s, r_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step_b_vae_cap(model, device, data_loader, loss_fun):\n",
    "    model.train()\n",
    "    r_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            #Forward Pass\n",
    "            output = model(data)\n",
    "            # BCE Loss\n",
    "            c, r_loss , g_loss = loss_fun(output, data)\n",
    "    return r_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   1 [209700/209700 (100%)]   Loss: 2723.6257   Rot_Loss: 2.4319   Capacity: 1.20   Test Loss : 260.2049   Time : 243.43s\n",
      "Train Epoch:   2 [209700/209700 (100%)]   Loss: 1984.8414   Rot_Loss: 2.3122   Capacity: 1.40   Test Loss : 271.4962   Time : 240.31s\n",
      "Train Epoch:   3 [209700/209700 (100%)]   Loss: 2132.4846   Rot_Loss: 1.3718   Capacity: 1.60   Test Loss : 267.0035   Time : 241.98s\n",
      "Train Epoch:   4 [209700/209700 (100%)]   Loss: 2398.1597   Rot_Loss: 1.3339   Capacity: 1.80   Test Loss : 264.5574   Time : 241.27s\n",
      "Train Epoch:   5 [209700/209700 (100%)]   Loss: 1819.6912   Rot_Loss: 1.0383   Capacity: 2.00   Test Loss : 272.7168   Time : 240.24s\n",
      "Train Epoch:   6 [209700/209700 (100%)]   Loss: 2232.4185   Rot_Loss: 1.3750   Capacity: 2.20   Test Loss : 272.0349   Time : 239.61s\n",
      "Train Epoch:   7 [209700/209700 (100%)]   Loss: 1936.7063   Rot_Loss: 0.9336   Capacity: 2.40   Test Loss : 259.9514   Time : 240.40s\n",
      "Train Epoch:   8 [209700/209700 (100%)]   Loss: 2238.2668   Rot_Loss: 1.4051   Capacity: 2.60   Test Loss : 278.2013   Time : 239.77s\n",
      "Train Epoch:   9 [209700/209700 (100%)]   Loss: 2173.6646   Rot_Loss: 1.1513   Capacity: 2.80   Test Loss : 277.6538   Time : 240.95s\n",
      "Train Epoch:  10 [209700/209700 (100%)]   Loss: 1289.2231   Rot_Loss: 0.9953   Capacity: 3.00   Test Loss : 273.0376   Time : 239.56s\n",
      "Train Epoch:  11 [209700/209700 (100%)]   Loss: 2104.2173   Rot_Loss: 1.6974   Capacity: 3.20   Test Loss : 267.5772   Time : 239.79s\n",
      "Train Epoch:  12 [209700/209700 (100%)]   Loss: 1519.7151   Rot_Loss: 2.1850   Capacity: 3.40   Test Loss : 280.8071   Time : 241.15s\n",
      "Train Epoch:  13 [209700/209700 (100%)]   Loss: 1490.3623   Rot_Loss: 1.0279   Capacity: 3.60   Test Loss : 279.1618   Time : 241.25s\n",
      "Train Epoch:  14 [209700/209700 (100%)]   Loss: 2049.6077   Rot_Loss: 1.1335   Capacity: 3.80   Test Loss : 264.9218   Time : 241.17s\n",
      "Train Epoch:  15 [209700/209700 (100%)]   Loss: 2028.3984   Rot_Loss: 1.7645   Capacity: 4.00   Test Loss : 275.8413   Time : 239.40s\n",
      "Train Epoch:  16 [209700/209700 (100%)]   Loss: 2351.1143   Rot_Loss: 1.4110   Capacity: 4.20   Test Loss : 271.5204   Time : 239.05s\n",
      "Train Epoch:  17 [209700/209700 (100%)]   Loss: 1877.4199   Rot_Loss: 0.9470   Capacity: 4.40   Test Loss : 270.0258   Time : 241.22s\n",
      "Train Epoch:  18 [209700/209700 (100%)]   Loss: 1582.0757   Rot_Loss: 1.8545   Capacity: 4.60   Test Loss : 263.8146   Time : 240.95s\n",
      "Train Epoch:  19 [209700/209700 (100%)]   Loss: 1838.0491   Rot_Loss: 1.7648   Capacity: 4.80   Test Loss : 272.6505   Time : 241.27s\n",
      "Train Epoch:  20 [209700/209700 (100%)]   Loss: 1870.6630   Rot_Loss: 1.0308   Capacity: 5.00   Test Loss : 269.9927   Time : 239.85s\n",
      "Train Epoch:  21 [209700/209700 (100%)]   Loss: 2427.2397   Rot_Loss: 1.6488   Capacity: 5.20   Test Loss : 260.8111   Time : 239.49s\n",
      "Train Epoch:  22 [209700/209700 (100%)]   Loss: 2179.2966   Rot_Loss: 1.4465   Capacity: 5.40   Test Loss : 262.7874   Time : 239.55s\n",
      "Train Epoch:  23 [209700/209700 (100%)]   Loss: 1503.5862   Rot_Loss: 1.7243   Capacity: 5.60   Test Loss : 264.2152   Time : 239.41s\n",
      "Train Epoch:  24 [209700/209700 (100%)]   Loss: 2163.7542   Rot_Loss: 1.0268   Capacity: 5.80   Test Loss : 270.8481   Time : 239.33s\n",
      "Train Epoch:  25 [209700/209700 (100%)]   Loss: 1731.0582   Rot_Loss: 1.2056   Capacity: 6.00   Test Loss : 267.2703   Time : 238.98s\n",
      "Train Epoch:  26 [203648/209700 ( 97%)]   Loss: 1870.0731   Rot_Loss: 1.4792   Capacity: 6.20\r"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss  = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    #LRG, forced params\n",
    "    start = time.time()\n",
    "    s, l = train_step_b_vae_cap(vae, device, data_loader_unlrg, optimizer, epoch, loss_fun=beta_vae_loss)\n",
    "    loss = test_step_b_vae_cap(vae, device, data_loader_lrg, loss_fun=beta_vae_loss)\n",
    "    train_loss.append(l)\n",
    "    test_loss.append(loss)\n",
    "    t = time.time() - start\n",
    "    sys.stdout.write('{}   Test Loss : {:4.4f}   Time : {:.2f}s\\n'.format(s, loss, t))\n",
    "    beta_vae_loss.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1#6\n",
    "s, l = sample[0][a:a+1], sample[1][a:a+1]\n",
    "with torch.no_grad():\n",
    "    e = vae.encode(s.to(device))[0]\n",
    "    d = vae.decode(e)\n",
    "f, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(s[0][0])\n",
    "ax[1].imshow(d.cpu()[0][0])\n",
    "ax[2].imshow(s[0][0] - d.cpu()[0][0], cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "ax[2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
