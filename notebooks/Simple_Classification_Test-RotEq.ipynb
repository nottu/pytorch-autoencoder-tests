{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_fwf, DataFrame\n",
    "from tqdm   import tqdm_notebook as tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage.io import imsave\n",
    "from skimage.filters import gaussian as gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import filters\n",
    "from skimage.morphology import opening, closing, disk, binary_dilation, flood\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from VAE.rg_dataset import LRG, BasicDataset\n",
    "from RotEqNet.layers_2D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "aug = 10\n",
    "data_path = '../data/'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/lrg:\t1442/1442\n"
     ]
    }
   ],
   "source": [
    "lrg_data_set   = LRG(112, rd_sz=128, use_kittler=True, n_aug=aug, blur=False, \n",
    "                     catalog_dir=data_path + 'catalog/mrt-table3.txt', \n",
    "                     file_dir=data_path + 'lrg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = lrg_data_set.get_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BasicDataset(X_train, y_train, n_aug=10, sz=112) #\n",
    "test_dataset  = BasicDataset(X_test,  y_test,  n_aug=5,  sz=112)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader  = data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAXdklEQVR4nO3dX4xcZ3nH8e8zM/t/vbbXiZONHWKnuEkMKIW6EAJCKSYt0IpwUVCQqFxIlRvaUoTUJu1F1QukXCAKF6WVxb+oRUAaoiaKWig1Tf+oNOAQIIkd4xA78SZre3H8f3ft3ZmnF8971juTXdvZ2fHM+v19JOvsOXPmzLPe3ed9znve8x5zd0QkX6V2ByAi7aUkIJI5JQGRzCkJiGROSUAkc0oCIplrWRIws/ea2R4ze87M7mnV54hIc6wV4wTMrAz8HLgdGAV+BHzE3Xct+YeJSFMqLTruW4Hn3P15ADP7JnAHMG8S6LYe72WgRaGICMBJjv7S3a9s3N6qJLAOODBnfRR429wdzOxu4G6AXvp5m21tUSgiAvDv/uAL821vVZ+AzbOt7rzD3be7+xZ339JFT4vCEJELaVUSGAWunbO+Hni5RZ8lIk1oVRL4EbDJzDaaWTdwJ/BIiz5LRJrQkj4Bd58xsz8CvguUga+4+zOt+CwRaU6rOgZx938B/qVVxxeRpaERgyKZUxIQyZySgEjmlAREMqckIJI5JQGRzCkJiGROSUAkc0oCIplTEhDJnJKASOaUBEQypyQgkjklAZHMKQmIZE5JQCRzSgIimVMSEMmckoBI5pQERDKnJCCSOSUBkcwpCYhkTklAJHNKAiKZUxIQyZySgEjmlAREMqckIJI5JQGRzC06CZjZtWb2H2a228yeMbNPpu3DZvY9M9ublquXLlwRWWrNVAIzwKfd/SbgFuATZrYZuAfY4e6bgB1pXUQ61KKTgLuPufuP09cngd3AOuAO4P602/3AB5sNUkRaZ0n6BMxsA/Bm4HHgKncfg0gUwNoF3nO3me00s53TnFmKMERkEZpOAmY2CHwb+FN3P3Gx73P37e6+xd23dNHTbBgiskhNJQEz6yISwNfd/aG0+ZCZjaTXR4DDzYUoIq3UzNUBA74M7Hb3z8156RFgW/p6G/Dw4sMTkVarNPHedwC/DzxlZj9J2/4CuA94wMzuAl4EPtRciCLSSotOAu7+P4At8PLWxR5XRC4tjRgUyZySgEjmlAREMqckIJI5JQGRzCkJiGROSUAkc0oCIplTEhDJnJKASOaUBEQypyQgkjklAZHMKQmIZE5JQCRzSgIimVMSEMmckoBI5pQERDKnJCCSOSUBkcwpCYhkTklAJHNKAiKZUxIQyZySgEjmlAREMqckIJI5JQGRzCkJiGSu6SRgZmUze9LMHk3rw2b2PTPbm5armw9TRFplKSqBTwK756zfA+xw903AjrQuIh2qqSRgZuuB3wG+NGfzHcD96ev7gQ828xki0lrNVgKfB/4MqM3ZdpW7jwGk5dr53mhmd5vZTjPbOc2ZJsMQkcVadBIws98FDrv7E4t5v7tvd/ct7r6li57FhiEiTao08d53AB8ws/cDvcCQmf0jcMjMRtx9zMxGgMNLEaiItMaiKwF3v9fd17v7BuBO4Pvu/lHgEWBb2m0b8HDTUYpIy7RinMB9wO1mthe4Pa2LSIdq5nRglrs/BjyWvj4CbF2K44q8FuWrog/arxqODT/fD0BtaqpNES0PGjEokrklqQRELoXy6hh8akODaUO57vWz16wCYGIkrjatnFoHQOX0JAB+dhqA6vh4y2NdTlQJiGROlYAsGzM3vg6Aozf1x3qfxQtev1+pGhuqv3FlWo/tfYejEqh8X5XAXKoERDKnSkCWvWpfLM8OxXJmICqByulo43qOxvZapQuAgXf/emz/6b54/5FXLlGknUlJQJYNL0f5X+2O9WpvLKdXFMu4haU2NBOvD0QSqHWV0/vTejkOUJlYD0C5En8G1UN5Dm7V6YBI5lQJSOeyaPlLg3FJ8MyKKOdnBmL79EDsNj2YKoC+dDNr6i+kO9anZ6e1iYqgPBk7HH99dDAOla+J7ROT1E6dil29obfxMqZKQCRzqgSkYxUVwOQ7bwTgxHXx6zpbAQxFS18dSBVAV415pe3VvtQn0BOVwExvLE++LjoXelbdSN9/PRv7nDy5VN9Gx1MlIJI5VQLSlMrG6wCoXjFUt72054XYfuIEANYVPfJ2w/UAeOqxL52apLr3eQDKm+K12so4V58ejPdMrYl9q8XgoNR0lc6mqwWpMpjtC2hUjCnqjvP8syvrX/A0+tjLZbrfGDFUnh+LY2dwxUCVgEjmVAnIeZWvjKG31h0985Tq242pjVcAcHokXrd0Wr7qTPS4V47Eeb33x3n3qV+JiqHaHa1wz9Fe+iZi38nroht/6op0FSCdu9e66mMqnY2lVdO5fRoP4KXUo19p6NmfSaVAGj5cS6/XutLxy8USTq+POFceSYMPVAmIyOVOlYCc15k3xU07k2ujOfbi/LpoPhrOw4vtx94Qt/Warzr/8Ye7OHPrtfXHWODcvpQmpS5+aaej64Cuk2ncQBoH4IMzde+zqXLdfpXTaZmGBFSmPMV6rpLROAERyYYqAalTXhNTc03fFBXAqfXRQ1+0ul6q71GfrQSK0/HUqhbn7aWZ1MoWg/kaGlgvgdXsVdvmLgtWK44d+3fNHsvq9q9W63+tKxPxejFSsLi1ePZ4qXDoOVFlxc+iD6B28PLvCyioEhDJnCqBTBXX7cvXRs+8V6JpL67RF1N0FRVAcY1+tpUuGu+iGSnOpdN4/0oqDYrKoXw2VQTVC8dWtNRe9OYX261Yj2OVi2NZEUxq6afTMrXwNlN/XBqqktmKYNqpjR+JXSYmLhzoZUKVgEjmVAlkpqgASsPRa39qc0zTXe2pb+lrlWK9oQKon9vznOJ8PN3rX1zDLxe97MVVhbQ81woz2xN/rmc+FuViPED6La0WLX1jx/2k1x28FrOIUTnN/LE3XH0oqpPK6SpUL6JUucyoEhDJnCqBzJTXjwBwurECmDNqDs6NpvP0G7JgBZAUrWk5Peejklrnoi+gNNOwf3FeXvVXXTEojuWz5+rp2KkyqDXEUow+LCYYJVUAlQmv+96KKqX4XorPGRiLA3c9sZfa5OR5v8/LkSoBkcypEshIedP158bnr5q/aS/6AmbS5J2N4/YvyOdfFhXB4PNxn76dSc17tbbg6DzviaZ7YkO63yA9wb6xT6CoJPxs/fbiakD/aJQnlsYsnNjQW7dfeSrKlJzmEJhLlYBI5lQJXMZKvdHildIowMmNw0yuiR950eI3OndvfXHNPa1XF9iv6O1P5/hFi993NN5QOZWWp1OnQHpIaPUirsMX8ff1vh6AqSujPClmCJqNpVZfGlj9xQK6xmJOA47E3OMrKtfV7V9+JToR8rsuEFQJiGSuqUrAzFYBXwLeSJz9fRzYA3wL2ADsBz7s7kebilIWpagAjt8Sd+nN9NnsvfMLKXrMu04tcJ6eKoDpNONvLfW4F/cK9B6NkmDFj0bjM196ue79C8wCOK/ZR4rvfDqO/eY3AHB642B9zAvc8De7PfU5FA8ZKf1n/cNGcq0ACs1WAl8AvuPuNwI3A7uBe4Ad7r4J2JHWRaRDLboSMLMh4F3AHwC4+1ngrJndAdyWdrsfeAz482aClEunaD2LuwEbr8nP3tlXtLKpsOg9Fm380OMH4n0teLRX6Rdx7KGD/fO+Xr16DfDqSkHOr5lK4HpgHPiqmT1pZl8yswHgKncfA0jLtfO92czuNrOdZrZzmjNNhCEizWimT6ACvAX4Y3d/3My+wGso/d19O7AdYMiG85nG5VIqFc/iq78PYN5dq/Uj+6xYn23x6+fpK0qB4qpA97F4Y2MfwFIqZi6mWDYoz0RwA40vHMvz+v/FaqYSGAVG3f3xtP4gkRQOmdkIQFrmMzuDyDK06ErA3Q+a2QEzu8Hd9wBbgV3p3zbgvrR8eEkilYtWXF/3wbiuXszae973FPfcTzdcc68Vr9fSMr0+UAwUKGb7aX8fe3V8PL4olsX2NsSynDQ7WOiPga+bWTfwPPAxorp4wMzuAl4EPtTkZ4hICzWVBNz9J8CWeV7a2sxxpTl2fZof8FdjzoDZOwDnzqb7GvUdimv25X0HAZjYEqPuZno13my5009QJHO6d2AZq4xcDUB1fTwlqFaJnD4xnJ7htzJKgGJ0X2na5/T+p+VFVgZ2Jt5Qe+UYAAO7or/Bu+JXyE7Hffgz87xXOpsqAZHMqRJYxmpr4pz/6E0xQq7W8NMsZtIp7sOfGbDZmX8a7w1ofLLQ7PX/49G2l05FS1+djpsEZva9sBTfgnQAJYFlrHi899nB+pt5Gm/zLUyurVGeSqcGZ+unAp/tPKzWP02kb3c8oruVg4CkvXQ6IJI5VQLLUOnXNgNwYlM8Pns6Zt/izOp0y+xA1PLeVd/rV14xzfRk/MhPW8wb1v9y/WPFKpPxnpX/17obgaSzqBIQyZwqgWWgtCJafFsflwRPbYiOwMnh1BeQJgOdWRNzgV05chyA1w3FXC7dacbNVd2TnJiOIcW/uCZuuz3UH5cXi76Cs+myYv/BuPmzvDrKjPJ4VATVQ7oV5HKjSkAkc6oEOtjsRKFXRqt97E2xPDNUXA1I5/OpQ797RVy+u/XqfQC8f+VPAVhbPgXAytI002kWkOfXxtRjf99/GwCHJqK6OPzLaPlfqsTEHYOjMSho9VOp00CVwGVHlYBI5lQJdLDZG4Guj0FBxUQfVrvwrcEAQ6UYGXRTd+T6Cv2c8pjFqZrmfv34Nf8NwAPjbwXg0PjKeHPDtN1cYIJSWb5UCYhkTpVAJzsSN+v0DcS43xO/EhNnzfSmnvy4aMCZtdH7f8v6uLZ/29CzAFzfFZVAj52bcGuQONY1lagIyhYTcAx3xwM4PI0YrKTncq7cH8coHYi+AE3QcflRJSCSOVUCHay4Jl/pjpsCajdEi15LNwSdXRUn7r1XRyv+gSt+AsCtvYcAWFt+1ZSbr3Is3XBQSnONl3vq2/pSuoWYyalFfQ/S+VQJiGROlcBykKYKr3bXPza8uiJa6XWrY4Tg23qjT2BteeGHb5zxuDX4hZk41r+euLnu9WvWxLHGV8U4gVc2RzWxZiauVBSPBJPLhyoBkcypElgOyjFab6YvVQL9abxAas2ff/kKAP5m5W8CsLk/7v3f3PsSAO/qvfBHPHX0GgAO7I9jDY/FZ6x5Mh70UTwCTFcHLj+qBEQyp0pgOUgP+ChmASpmBbK0rE3Ej/Gx0dcD8OLq9Ejy4Tiv77VdANzQNcMr1WjLfzx1PQBPHItz/f1jcV9C/wtxS+Kan8UVh9L+qCqqCzz6S5Y/VQIimVMlsBykB21WJqIS6D6RrhakkYO1NBzg5KG4KvB8elt3Oa4EnKxGp8DvrdzJ/pmYP+ChQ28B4Ol96wAoH4zxAoOjqb/hB3EHovoALn+qBEQyp0pgOailh4EWDwxpXE6V63Y/eTgqgmeqkeOLmYUeLd3M/x6JvoBnd10LQPlk7NN/MKqKvvHpFnwD0slUCYhkTpXAMlA7cRKAVT89Ehtujp78Wnd9Dq/2xfl8zdLjyH4ZVwd+eDYeHvqzvhFOHokOhL6DUT2U42ZCKpPpykO1/qEkcvlTJSCSuaYqATP7FPCHxDw0TwEfA/qBbwEbgP3Ah93TNDayKLWTUQmwO5ZDaX6BymS09FOrolU/tT5y+uyTiEopx4/Hj3mip5/ek3Hu3zueWv70BNHeo9Hv0P1K3C2oeiAfi64EzGwd8CfAFnd/I1AG7gTuAXa4+yZgR1oXkQ7VbJ9ABegzs2miAngZuBe4Lb1+P/AY8OdNfo7M4elOvr6dsT44FDME97znJgCm+9P4gXIxniD2q3Yblalo43uOF5VALFc8FTMMVfcWowwkF4uuBNz9JeCzwIvAGHDc3f8NuMrdx9I+Y8Da+d5vZneb2U4z2znNmcWGISJNWnQlYGargTuAjcAx4J/M7KMX+3533w5sBxiyYZ2CNqE2MQHA0A/S48Ir8WOtrY7xAsc3x2zFtbLPjjWoTEQfwOCumL2odlDPE8hVM1cH3gPsc/dxd58GHgJuBQ6Z2QhAWuq3S6SDNdMn8CJwi5n1A5PAVmAncBrYBtyXlg83G6Scn89EF//M2MG67eXj0VcwlOYjmLq6f3YcQO9o3BVYPRB3Cfr02UsSq3SeRScBd3/czB4EfgzMAE8S5f0g8ICZ3UUkig8tRaAi0hrm3v7T8SEb9rfZ1naHcdmz33gTpdPpCUS7ft7maORS+3d/8Al339K4XcOGM2JP7dUgIHkVDRsWyZwqgYzUpvQAEXk1VQIimVMSEMmckoBI5pQERDKnJCCSOSUBkcwpCYhkTklAJHNKAiKZUxIQyZySgEjmlAREMqckIJI5JQGRzCkJiGROSUAkc0oCIplTEhDJnJKASOaUBEQypyQgkjklAZHMKQmIZE5JQCRzSgIimVMSEMncBZOAmX3FzA6b2dNztg2b2ffMbG9arp7z2r1m9pyZ7TGz325V4CKyNC6mEvga8N6GbfcAO9x9E7AjrWNmm4E7gTek93zRzMpLFq2ILLkLJgF3/y/glYbNdwD3p6/vBz44Z/s33f2Mu+8DngPeukSxikgLLLZP4Cp3HwNIy7Vp+zrgwJz9RtO2VzGzu81sp5ntnObMIsMQkWYtdcegzbPN59vR3be7+xZ339JFzxKHISIXa7FJ4JCZjQCk5eG0fRS4ds5+64GXFx+eiLTaYpPAI8C29PU24OE52+80sx4z2whsAn7YXIgi0kqVC+1gZt8AbgOuMLNR4K+A+4AHzOwu4EXgQwDu/oyZPQDsAmaAT7h7tUWxi8gSuGAScPePLPDS1gX2/wzwmWaCEpFLRyMGRTKnJCCSOSUBkcwpCYhkTklAJHNKAiKZUxIQyZySgEjmlAREMqckIJI5JQGRzCkJiGROSUAkc0oCIplTEhDJnJKASOaUBEQyZ+7zTgZ8aYMwGwdOA79sdywLuALFthiK7bVrZVzXufuVjRs7IgkAmNlOd9/S7jjmo9gWR7G9du2IS6cDIplTEhDJXCclge3tDuA8FNviKLbX7pLH1TF9AiLSHp1UCYhIGygJiGSuI5KAmb3XzPaY2XNmdk8b47jWzP7DzHab2TNm9sm0fdjMvmdme9NydRtjLJvZk2b2aCfFZmarzOxBM3s2/f+9vYNi+1T6eT5tZt8ws952xWZmXzGzw2b29JxtC8ZiZvemv4s9ZvbbrYip7UnAzMrA3wLvAzYDHzGzzW0KZwb4tLvfBNwCfCLFcg+ww903ATvSert8Etg9Z71TYvsC8B13vxG4mYix7bGZ2TrgT4At7v5GoAzc2cbYvga8t2HbvLGk3707gTek93wx/b0sLXdv6z/g7cB356zfC9zb7rhSLA8DtwN7gJG0bQTY06Z41qdfkncDj6ZtbY8NGAL2kTqa52zvhNjWAQeAYeLZm48Cv9XO2IANwNMX+n9q/FsAvgu8fanjaXslwLkfUmE0bWsrM9sAvBl4HLjK3ccA0nJtm8L6PPBnQG3Otk6I7XpgHPhqOlX5kpkNdEJs7v4S8Fni6dljwHF3/7dOiG2OhWK5JH8bnZAEbJ5tbb1uaWaDwLeBP3X3E+2MpWBmvwscdvcn2h3LPCrAW4C/c/c3E/eBtPOUaVY6v74D2AhcAwyY2UfbG9VFuyR/G52QBEaBa+esrwdeblMsmFkXkQC+7u4Ppc2HzGwkvT4CHG5DaO8APmBm+4FvAu82s3/skNhGgVF3fzytP0gkhU6I7T3APncfd/dp4CHg1g6JrbBQLJfkb6MTksCPgE1mttHMuomOkEfaEYiZGfBlYLe7f27OS48A29LX24i+gkvK3e919/XuvoH4P/q+u3+0Q2I7CBwwsxvSpq3Ark6IjTgNuMXM+tPPdyvRadkJsRUWiuUR4E4z6zGzjcAm4IdL/umXuqNmgY6S9wM/B34B/GUb43gnUW79DPhJ+vd+YA3RIbc3LYfb/P91G+c6BjsiNuDXgJ3p/+6fgdUdFNtfA88CTwP/APS0KzbgG0TfxDTR0t91vliAv0x/F3uA97UiJg0bFslcJ5wOiEgbKQmIZE5JQCRzSgIimVMSEMmckoBI5pQERDL3/3aPpl47tRN3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = iter(test_dataloader).next()\n",
    "plt.imshow(sample[0].numpy()[10][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, epoch, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_inputs=0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        running_inputs += len(labels.data)\n",
    "        \n",
    "        running_acc = (1.0 * running_corrects)/running_inputs\n",
    "        \n",
    "        s = 'Train Epoch: {:3d} ({:3.0f}%)\\tLoss:\\t{:4.4f}\\trLoss: {:4.2f}\\tTrain Acc: {:.4f}'\n",
    "        s = s.format(epoch,\n",
    "                100. * batch_idx / len(dataloader), loss.item(), running_loss, running_acc)\n",
    "        sys.stdout.write('{}\\r'.format(s))\n",
    "        sys.stdout.flush()\n",
    "    return running_loss, running_corrects, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, optimizer, epoch, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_inputs=0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        running_inputs += len(labels.data)\n",
    "        \n",
    "        running_acc = (1.0 * running_corrects)/running_inputs\n",
    "\n",
    "    return running_loss, running_acc#, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotEqDeepClassifier(nn.Module):\n",
    "    ''' Somewhat inspired in VGG\n",
    "        Adds option for STN network\n",
    "    '''\n",
    "    def __init__(self, nf=None, k=3, num_classes=6, lt_dim=8, batchnorm=True, in_channels=1, non_linearity=nn.ReLU):\n",
    "        super(RotEqDeepClassifier, self).__init__()\n",
    "        \n",
    "        self.non_linearity = non_linearity\n",
    "                \n",
    "        if nf == None:\n",
    "            nf = [32, 'M', 64, 'M', 128, 128, 'M', 'R', 256, 256, 'M']\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(nf[-2] * 7 * 7, lt_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(lt_dim, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "        layers = self.__make_layers(nf, batchnorm, k=k)\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def __make_layers(self, nf, batch_norm, in_channels=1, mode=1, k=3):\n",
    "        layers = []\n",
    "        use_rot = True\n",
    "        for v in nf:\n",
    "#             print('=============================',v,'====================')\n",
    "            if v == 'R':\n",
    "                use_rot = False\n",
    "                conv2d = RotConv(in_channels, in_channels, kernel_size=[k, k], padding=k//2, mode=mode, n_angles = 17)\n",
    "                layers += [conv2d, Vector2Magnitude()]\n",
    "            elif v == 'M' :\n",
    "                if use_rot:\n",
    "                    layers += [VectorMaxPool(kernel_size=2, stride=2)] #keep kernel_size @ 2\n",
    "                else:\n",
    "                    layers += [nn.MaxPool2d(kernel_size=2, stride=2)] #keep kernel_size @ 2\n",
    "            else :\n",
    "                if use_rot:\n",
    "                    conv2d = RotConv(in_channels, v, kernel_size=[k, k], padding=k//2, mode=mode, n_angles = 17)\n",
    "                else:\n",
    "                    conv2d = nn.Conv2d(in_channels, v, kernel_size=k, padding=k//2)\n",
    "                if batch_norm:\n",
    "                    if use_rot:\n",
    "                        layers += [conv2d, VectorBatchNorm(v)]\n",
    "                    else:\n",
    "                        layers += [conv2d, nn.BatchNorm2d(v), self.non_linearity(inplace=True)]\n",
    "                else:\n",
    "                    if use_rot:\n",
    "                        layers += [conv2d]\n",
    "                    else:\n",
    "                        layers += [conv2d, self.non_linearity(inplace=True)]\n",
    "                in_channels = v\n",
    "                mode = 2\n",
    "        return layers\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.features(x)\n",
    "        y = self.avgpool(y)\n",
    "        y = torch.flatten(y, 1)\n",
    "        y = self.classifier(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RotEqDeepClassifier(batchnorm=False, k=9).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=1E-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# def pretty_size(size):\n",
    "# \t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "# \tassert(isinstance(size, torch.Size))\n",
    "# \treturn \" × \".join(map(str, size))\n",
    "\n",
    "# def dump_tensors(gpu_only=True):\n",
    "# \t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "# \timport gc\n",
    "# \ttotal_size = 0\n",
    "# \tfor obj in gc.get_objects():\n",
    "# \t\ttry:\n",
    "# \t\t\tif torch.is_tensor(obj):\n",
    "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "# \t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "# \t\t\t\t\ttotal_size += obj.numel()\n",
    "# \t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "# \t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "# \t\t\t\t\ttotal_size += obj.data.numel()\n",
    "# \t\texcept Exception as e:\n",
    "# \t\t\tpass        \n",
    "# \tprint(\"Total size:\", total_size)\n",
    "# dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = model.features(sample[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   1 (100%)\tLoss:\t1.2460\trLoss: 15799.97\tTrain Acc: 0.3511 Test Acc: 0.4258\tTime: 659.1836\n",
      "Train Epoch:   2 (100%)\tLoss:\t1.1889\trLoss: 13097.16\tTrain Acc: 0.5087 Test Acc: 0.5797\tTime: 661.5944\n",
      "Train Epoch:   3 (100%)\tLoss:\t1.2790\trLoss: 12135.39\tTrain Acc: 0.5331 Test Acc: 0.4665\tTime: 662.4409\n",
      "Train Epoch:   4 (100%)\tLoss:\t1.4867\trLoss: 11751.61\tTrain Acc: 0.5563 Test Acc: 0.5178\tTime: 662.6539\n",
      "Train Epoch:   5 (100%)\tLoss:\t1.5887\trLoss: 12533.54\tTrain Acc: 0.5450 Test Acc: 0.3992\tTime: 662.6925\n",
      "Train Epoch:   6 (100%)\tLoss:\t1.8807\trLoss: 12166.78\tTrain Acc: 0.5421 Test Acc: 0.4547\tTime: 662.2765\n",
      "Train Epoch:   7 (100%)\tLoss:\t0.9692\trLoss: 11864.79\tTrain Acc: 0.5587 Test Acc: 0.4288\tTime: 662.3713\n",
      "Train Epoch:   8 (100%)\tLoss:\t0.7108\trLoss: 11565.65\tTrain Acc: 0.5742 Test Acc: 0.4462\tTime: 662.5547\n",
      "Train Epoch:   9 (100%)\tLoss:\t1.0685\trLoss: 11195.90\tTrain Acc: 0.5860 Test Acc: 0.5322\tTime: 662.8033\n",
      "Train Epoch:  10 (100%)\tLoss:\t1.2483\trLoss: 11087.29\tTrain Acc: 0.5914 Test Acc: 0.4970\tTime: 662.6931\n",
      "Train Epoch:  11 (100%)\tLoss:\t2.2314\trLoss: 10600.21\tTrain Acc: 0.6103 Test Acc: 0.5297\tTime: 662.6547\n",
      "Train Epoch:  12 (100%)\tLoss:\t2.0189\trLoss: 10169.74\tTrain Acc: 0.6207 Test Acc: 0.5581\tTime: 662.8317\n",
      "Train Epoch:  13 (100%)\tLoss:\t0.8429\trLoss: 9779.25\tTrain Acc: 0.6313 Test Acc: 0.5288\tTime: 662.7110\n",
      "Train Epoch:  14 (100%)\tLoss:\t1.2458\trLoss: 9248.57\tTrain Acc: 0.6530 Test Acc: 0.5479\tTime: 662.9843\n",
      "Train Epoch:  15 (100%)\tLoss:\t0.3631\trLoss: 9037.79\tTrain Acc: 0.6511 Test Acc: 0.5966\tTime: 662.6487\n",
      "Train Epoch:  16 (100%)\tLoss:\t0.6274\trLoss: 8688.84\tTrain Acc: 0.6631 Test Acc: 0.5686\tTime: 669.0786\n",
      "Train Epoch:  17 (100%)\tLoss:\t0.2880\trLoss: 8436.25\tTrain Acc: 0.6643 Test Acc: 0.5369\tTime: 662.8321\n",
      "Train Epoch:  18 ( 22%)\tLoss:\t1.0147\trLoss: 1832.43\tTrain Acc: 0.6754\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-89e9d9e448d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest_l\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_c\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-59d5d0ad70ad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.half()  # convert to half precision\n",
    "# for layer in model.modules():\n",
    "#     if isinstance(layer, nn.BatchNorm2d) or isinstance(layer, VectorBatchNorm):\n",
    "#         layer.float()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.time()\n",
    "    train_l, train_c, train_s = train(model, train_dataloader, optimizer, epoch, criterion)\n",
    "    test_l,  test_c           = test(model,  test_dataloader,  optimizer, epoch, criterion)\n",
    "    t = time.time() - start\n",
    "    print(train_s, 'Test Acc: {:.4f}\\tTime: {:.4f}'.format(test_c, t))\n",
    "    del train_l, train_c, test_l,  test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
